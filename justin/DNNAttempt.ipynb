{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Name: /physical_device:GPU:0   Type: GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "print(tf.__version__)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (5,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pkSeqID         stime flgs proto            saddr  sport           daddr  \\\n",
      "0        1  1.526344e+09    e   arp    192.168.100.1    NaN   192.168.100.3   \n",
      "1        2  1.526344e+09    e   tcp    192.168.100.7    139   192.168.100.4   \n",
      "2        3  1.526344e+09    e   udp  192.168.100.149  51838  27.124.125.250   \n",
      "3        4  1.526344e+09    e   arp    192.168.100.4    NaN   192.168.100.7   \n",
      "4        5  1.526344e+09    e   udp   192.168.100.27  58999   192.168.100.1   \n",
      "\n",
      "   dport  pkts  bytes  ... spkts  dpkts  sbytes  dbytes       rate     srate  \\\n",
      "0    NaN     4    240  ...     2      2     120     120   0.002508  0.000836   \n",
      "1  36390    10    680  ...     5      5     350     330   0.006190  0.002751   \n",
      "2    123     2    180  ...     1      1      90      90  20.590960  0.000000   \n",
      "3    NaN    10    510  ...     5      5     210     300   0.006189  0.002751   \n",
      "4     53     4    630  ...     2      2     174     456   0.005264  0.001755   \n",
      "\n",
      "      drate  attack  category  subcategory  \n",
      "0  0.000836       0    Normal       Normal  \n",
      "1  0.002751       0    Normal       Normal  \n",
      "2  0.000000       0    Normal       Normal  \n",
      "3  0.002751       0    Normal       Normal  \n",
      "4  0.001755       0    Normal       Normal  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "(1000000, 35)\n",
      "Index(['pkSeqID', 'stime', 'flgs', 'proto', 'saddr', 'sport', 'daddr', 'dport',\n",
      "       'pkts', 'bytes', 'state', 'ltime', 'seq', 'dur', 'mean', 'stddev',\n",
      "       'smac', 'dmac', 'sum', 'min', 'max', 'soui', 'doui', 'sco', 'dco',\n",
      "       'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'srate', 'drate',\n",
      "       'attack', 'category', 'subcategory'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# feature_labels = np.genfromtxt('UNSW_2018_IoT_Botnet_Dataset_Feature_Names.csv', delimiter=',')\n",
    "# train_file_path = tf.keras.utils.get_file(\"UNSW_2018_IoT_Botnet_Dataset_Feature_Names.csv\", )\n",
    "# data = np.genfromtxt('UNSW_2018_IoT_Botnet_Dataset_62.csv', delimiter=',')\n",
    "\n",
    "base_dir = 'G:/Deel Learning Project/Entire Dataset'    \n",
    "\n",
    "feature_labels = pd.read_csv(\"UNSW_2018_IoT_Botnet_Dataset_Feature_Names.csv\", sep=',')\n",
    "\n",
    "files = []\n",
    "frame = pd.DataFrame()\n",
    "\n",
    "#set range to 74 for all files (memory issue)\n",
    "for i in range(1, 2):\n",
    "    files.append(pd.read_csv(f\"UNSW_2018_IoT_Botnet_Dataset_{i}.csv\", sep=',', header=None))\n",
    "\n",
    "frame = frame.append(files)\n",
    "\n",
    "# for i in range(1, 74):\n",
    "#     pd.read_csv(f\"UNSW_2018_IoT_Botnet_Dataset_{i}.csv\", sep=',', header=None).to_csv('temp.csv', mode='a', header=None)\n",
    "    \n",
    "# frame = pd.read_csv(\"temp.csv\", sep=',', header=None)\n",
    "\n",
    "frame.columns = feature_labels.columns\n",
    "\n",
    "# print(labels)\n",
    "print(frame.head())\n",
    "print(frame.shape)\n",
    "print(frame.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          stime proto  pkts  bytes state         ltime  seq          dur  \\\n",
      "0  1.526344e+09   arp     4    240   CON  1.526345e+09    9  1195.996582   \n",
      "1  1.526344e+09   tcp    10    680   CON  1.526346e+09   10  1453.945923   \n",
      "2  1.526344e+09   udp     2    180   CON  1.526344e+09   11     0.048565   \n",
      "3  1.526344e+09   arp    10    510   CON  1.526346e+09   12  1454.080322   \n",
      "4  1.526344e+09   udp     4    630   CON  1.526345e+09   14   569.933960   \n",
      "\n",
      "       mean    stddev  ...  spkts  dpkts  sbytes  dbytes       rate     srate  \\\n",
      "0  0.000006  0.000002  ...      2      2     120     120   0.002508  0.000836   \n",
      "1  0.000028  0.000008  ...      5      5     350     330   0.006190  0.002751   \n",
      "2  0.048565  0.000000  ...      1      1      90      90  20.590960  0.000000   \n",
      "3  0.000238  0.000022  ...      5      5     210     300   0.006189  0.002751   \n",
      "4  0.098505  0.080150  ...      2      2     174     456   0.005264  0.001755   \n",
      "\n",
      "      drate  attack  category  subcategory  \n",
      "0  0.000836       0    Normal       Normal  \n",
      "1  0.002751       0    Normal       Normal  \n",
      "2  0.000000       0    Normal       Normal  \n",
      "3  0.002751       0    Normal       Normal  \n",
      "4  0.001755       0    Normal       Normal  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "#Drop Seq ID\n",
    "frame = frame.drop(['pkSeqID'], axis = 1)\n",
    "# feature_labels.pop('pkSeqId')\n",
    "\n",
    "#Drop Ips\n",
    "frame = frame.drop(['saddr', 'daddr'], axis = 1)\n",
    "\n",
    "#Drop blank fields\n",
    "frame = frame.drop(['smac', 'dmac', 'soui', 'doui', 'sco', 'dco'], axis = 1)\n",
    "\n",
    "#Drop flags and ports because they contain NaNs\n",
    "frame = frame.drop(['flgs', 'sport', 'dport'], axis = 1)\n",
    "\n",
    "print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode protocol\n",
    "\n",
    "# frame = pd.concat([frame ,pd.get_dummies(frame['proto'], prefix='proto',dummy_na=False)],axis=1).drop(['proto'],axis=1)\n",
    "# print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode state\n",
    "\n",
    "# frame = pd.concat([frame ,pd.get_dummies(frame['state'], prefix='state',dummy_na=False)],axis=1).drop(['state'],axis=1)\n",
    "# print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode category, skip if using pd.Categorical\n",
    "\n",
    "# frame = pd.concat([frame ,pd.get_dummies(frame['category'], prefix='category',dummy_na=False)],axis=1).drop(['category'],axis=1)\n",
    "\n",
    "# print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:\n",
      "\n",
      "0 Normal\n",
      "1 Reconnaissance\n",
      "          stime proto  pkts  bytes state         ltime  seq          dur  \\\n",
      "0  1.526344e+09   arp     4    240   CON  1.526345e+09    9  1195.996582   \n",
      "1  1.526344e+09   tcp    10    680   CON  1.526346e+09   10  1453.945923   \n",
      "2  1.526344e+09   udp     2    180   CON  1.526344e+09   11     0.048565   \n",
      "3  1.526344e+09   arp    10    510   CON  1.526346e+09   12  1454.080322   \n",
      "4  1.526344e+09   udp     4    630   CON  1.526345e+09   14   569.933960   \n",
      "\n",
      "       mean    stddev  ...       max  spkts  dpkts  sbytes  dbytes       rate  \\\n",
      "0  0.000006  0.000002  ...  0.000007      2      2     120     120   0.002508   \n",
      "1  0.000028  0.000008  ...  0.000042      5      5     350     330   0.006190   \n",
      "2  0.048565  0.000000  ...  0.048565      1      1      90      90  20.590960   \n",
      "3  0.000238  0.000022  ...  0.000261      5      5     210     300   0.006189   \n",
      "4  0.098505  0.080150  ...  0.178655      2      2     174     456   0.005264   \n",
      "\n",
      "      srate     drate  subcategory  target  \n",
      "0  0.000836  0.000836       Normal       0  \n",
      "1  0.002751  0.002751       Normal       0  \n",
      "2  0.000000  0.000000       Normal       0  \n",
      "3  0.002751  0.002751       Normal       0  \n",
      "4  0.001755  0.001755       Normal       0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#Make the target the 'attack' column (binary classification)\n",
    "def label_target(row):\n",
    "    if row['attack'] == 1:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# frame['target'] = frame.apply(lambda row: label_target(row), axis = 1)\n",
    "frame = frame.drop(['attack'], axis = 1)\n",
    "\n",
    "#Make the tartget column a categorical version of the 'category' column (classification)\n",
    "\n",
    "frame['target'] = pd.Categorical(frame['category'])\n",
    "\n",
    "print(\"Categories:\\n\")\n",
    "for i,cat in enumerate(frame['target'].cat.categories):\n",
    "    print(i, cat)\n",
    "\n",
    "frame['target'] = frame.target.cat.codes.astype(int)\n",
    "\n",
    "frame = frame.drop(['category'], axis = 1)\n",
    "\n",
    "#Remove the encoded categories and keep the target\n",
    "# frame = frame[frame.columns.drop(list(frame.filter(regex='category_')))]\n",
    "\n",
    "print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          stime proto  pkts  bytes state         ltime  seq          dur  \\\n",
      "0  1.526344e+09   arp     4    240   CON  1.526345e+09    9  1195.996582   \n",
      "1  1.526344e+09   tcp    10    680   CON  1.526346e+09   10  1453.945923   \n",
      "2  1.526344e+09   udp     2    180   CON  1.526344e+09   11     0.048565   \n",
      "3  1.526344e+09   arp    10    510   CON  1.526346e+09   12  1454.080322   \n",
      "4  1.526344e+09   udp     4    630   CON  1.526345e+09   14   569.933960   \n",
      "\n",
      "       mean    stddev  ...       min       max  spkts  dpkts  sbytes  dbytes  \\\n",
      "0  0.000006  0.000002  ...  0.000004  0.000007      2      2     120     120   \n",
      "1  0.000028  0.000008  ...  0.000022  0.000042      5      5     350     330   \n",
      "2  0.048565  0.000000  ...  0.048565  0.048565      1      1      90      90   \n",
      "3  0.000238  0.000022  ...  0.000199  0.000261      5      5     210     300   \n",
      "4  0.098505  0.080150  ...  0.018356  0.178655      2      2     174     456   \n",
      "\n",
      "        rate     srate     drate  target  \n",
      "0   0.002508  0.000836  0.000836       0  \n",
      "1   0.006190  0.002751  0.002751       0  \n",
      "2  20.590960  0.000000  0.000000       0  \n",
      "3   0.006189  0.002751  0.002751       0  \n",
      "4   0.005264  0.001755  0.001755       0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#Encode subcategory\n",
    "\n",
    "# frame = pd.concat([frame ,pd.get_dummies(frame['subcategory'], prefix='subcategory',dummy_na=False)],axis=1).drop(['subcategory'],axis=1)\n",
    "\n",
    "\n",
    "#Remove subcategory\n",
    "frame = frame.drop(['subcategory'], axis = 1)\n",
    "\n",
    "print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stime     float64\n",
      "proto      object\n",
      "pkts        int64\n",
      "bytes       int64\n",
      "state      object\n",
      "ltime     float64\n",
      "seq         int64\n",
      "dur       float64\n",
      "mean      float64\n",
      "stddev    float64\n",
      "sum       float64\n",
      "min       float64\n",
      "max       float64\n",
      "spkts       int64\n",
      "dpkts       int64\n",
      "sbytes      int64\n",
      "dbytes      int64\n",
      "rate      float64\n",
      "srate     float64\n",
      "drate     float64\n",
      "target      int32\n",
      "dtype: object\n",
      "      stime proto  pkts  bytes state     ltime  seq       dur      mean  \\\n",
      "0  0.000148   arp     4    240   CON  0.001800    9  0.616220  0.000001   \n",
      "1  0.000316   tcp    10    680   CON  0.002394   10  0.749125  0.000006   \n",
      "2  0.000323   udp     2    180   CON  0.000000   11  0.000025  0.009774   \n",
      "3  0.000325   arp    10    510   CON  0.002403   12  0.749194  0.000048   \n",
      "4  0.000448   udp     4    630   CON  0.001066   14  0.293650  0.019824   \n",
      "\n",
      "         stddev  ...           min       max  spkts  dpkts  sbytes  dbytes  \\\n",
      "0  8.001584e-07  ...  8.075216e-07  0.000001      2      2     120     120   \n",
      "1  3.200634e-06  ...  4.441369e-06  0.000008      5      5     350     330   \n",
      "2  0.000000e+00  ...  9.804321e-03  0.009713      1      1      90      90   \n",
      "3  8.801743e-06  ...  4.017420e-05  0.000052      5      5     210     300   \n",
      "4  3.206635e-02  ...  3.705717e-03  0.035731      2      2     174     456   \n",
      "\n",
      "           rate         srate         drate  target  \n",
      "0  2.006400e-09  8.360000e-10  1.672000e-09       0  \n",
      "1  4.952000e-09  2.751000e-09  5.502000e-09       0  \n",
      "2  1.647277e-05  0.000000e+00  0.000000e+00       0  \n",
      "3  4.951200e-09  2.751000e-09  5.502000e-09       0  \n",
      "4  4.211200e-09  1.755000e-09  3.510000e-09       0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#Normalize \n",
    "\n",
    "cols_to_normalize = ['stime', 'ltime', 'dur', 'mean', 'stddev',\n",
    "       'sum', 'min', 'max', 'rate', 'srate', 'drate']\n",
    "\n",
    "# cols_to_normalize = frame.columns\n",
    "\n",
    "print(frame.dtypes)\n",
    "\n",
    "#Mean min-max\n",
    "#frame=(df-df.min())/(df.max()-df.min())\n",
    "frame[cols_to_normalize] = frame[cols_to_normalize].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "#Mean normalization\n",
    "# normalized_df=(df-df.mean())/df.std()\n",
    "\n",
    "# normalized_frame = (frame-frame.min())/(frame.max()-frame.min())\n",
    "# frame[cols_to_normalize] = frame[cols_to_normalize].apply(lambda x: (x - x.mean()) / x.std()))\n",
    "\n",
    "print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      stime proto  pkts  bytes state     ltime  seq       dur      mean  \\\n",
      "0  0.000148   arp     4    240   CON  0.001800    9  0.616220  0.000001   \n",
      "1  0.000316   tcp    10    680   CON  0.002394   10  0.749125  0.000006   \n",
      "2  0.000323   udp     2    180   CON  0.000000   11  0.000025  0.009774   \n",
      "3  0.000325   arp    10    510   CON  0.002403   12  0.749194  0.000048   \n",
      "4  0.000448   udp     4    630   CON  0.001066   14  0.293650  0.019824   \n",
      "\n",
      "         stddev  ...           min       max  spkts  dpkts  sbytes  dbytes  \\\n",
      "0  8.001584e-07  ...  8.075216e-07  0.000001      2      2     120     120   \n",
      "1  3.200634e-06  ...  4.441369e-06  0.000008      5      5     350     330   \n",
      "2  0.000000e+00  ...  9.804321e-03  0.009713      1      1      90      90   \n",
      "3  8.801743e-06  ...  4.017420e-05  0.000052      5      5     210     300   \n",
      "4  3.206635e-02  ...  3.705717e-03  0.035731      2      2     174     456   \n",
      "\n",
      "           rate         srate         drate  target  \n",
      "0  2.006400e-09  8.360000e-10  1.672000e-09       0  \n",
      "1  4.952000e-09  2.751000e-09  5.502000e-09       0  \n",
      "2  1.647277e-05  0.000000e+00  0.000000e+00       0  \n",
      "3  4.951200e-09  2.751000e-09  5.502000e-09       0  \n",
      "4  4.211200e-09  1.755000e-09  3.510000e-09       0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# frame = frame.astype('float64')\n",
    "\n",
    "# print(frame.dtypes)\n",
    "\n",
    "print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640000 train examples\n",
      "160000 validation examples\n",
      "200000 test examples\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(frame, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')\n",
    "\n",
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('target')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import feature_column\n",
    "\n",
    "\n",
    "feature_columns = []\n",
    "frame.pop('target')\n",
    "\n",
    "# numeric cols\n",
    "for header in frame.columns:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# print(train_ds)\n",
    "# print(val_ds)\n",
    "# print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 20000 steps, validate for 5000 steps\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
